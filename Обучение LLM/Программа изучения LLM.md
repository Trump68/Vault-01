Ниже ‒ «дорожная карта» в форме вопросов. Ответив (или найдя ответ) на каждый из них, вы последовательно разберёте, из чего состоит трансформер, как он учится и почему стал стандартом в NLP и CV.

A. Почему вообще понадобился трансформер? 
1. Какие ограничения у RNN/LSTM и CNN при работе с длинными последовательностями?  
2. Что такое attention в принципе и как он решает проблему дальних зависимостей?  
3. Чем «self-attention повсюду» отличается от «attention поверх RNN»?

 B. Базовый строительный блок — self-attention
 4. Что обозначают Q, K, V (queries, keys, values)?  
5. Как вычисляется scaled dot-product attention и зачем делить на √d_k?  
6. Почему в конце стоит softmax и какую роль играет маскирование (masking)?  
7. Чем self-attention отличается от «обычного» (encoder-decoder) attention?  
8. Какие формы масок бывают (паддинги, causality, sparse)?

C. Multi-Head Attention 
9. Зачем «разбивать» пространство признаков на h голов?  
10. Как реализуется параллельное вычисление голов (матрицы W_q, W_k, W_v, concat, W_o)?  
11. Что будет, если голов слишком мало / слишком много?

D. Позиционная информация 
12. Почему чистая self-attention не знает о порядке токенов?  		
13. Как работают sinusoidal positional encodings из оригинальной статьи?  
14. Чем они отличаются от learnable абсолютных позиций (BERT) и относительных (Transformer-XL, ALiBi, RoPE)?  
15. Что даёт rotary/relative позиционирование при генерации длинных текстов?
> [!Ответ] 
>[Позиционная информация](Позиционная%20информация.md)

E. Слой трансформера 
16. Как устроена последовательность: LayerNorm → (Multi-Head) → residual → LayerNorm → FFN → residual?  
17. Зачем residual-соединения и LayerNorm в двух местах?  
18. Что такое position-wise Feed-Forward Network (FFN) и почему там используется (W₁, GELU/ReLU, W₂)?  
19. Как dropout встроен в каждый подпроцесс?

F. Архитектура encoder / decoder 
20. Чем чистый encoder (BERT) отличается от чистого decoder (GPT)?  
21. Как выглядит полный encoder-decoder (оригинальный Transformer для перевода)?  
22. Что такое cross-attention в декодере и как он «смотрит» на выходы энкодера?  
23. Где применяется causal mask и почему без неё модель «подглядывала бы в будущее»?

 G. Обучение 
  24. Какие задачи предобучения бывают: MLM, CLM, Seq2Seq, Permuted LM?  
25. Что такое teacher forcing и label smoothing?  
26. Зачем нужен learning-rate warm-up и линейный/косинусный decay?  
27. Почему почти всегда используют Adam/AdamW и weight decay ~10⁻²?  
28. Что измеряет perplexity, а что – token-level accuracy?  
29. Как выглядит батч (padding, attention_mask) и чем он отличается в training/inference?

H. Генерация и использование 
30. Как работают beam search, top-k, nucleus (p)-sampling, температура?  
31. Что такое greedy decoding и когда оно ломается?  
32. Почему декодер в режиме инференса по-одному добавляет токены (авторегрессия)?

I. Масштабирование и эффективность 
33. Почему self-attention O(N²) по памяти и FLOPs?  
34. Какие подходы уменьшают сложность: Sparse, Linformer, Performer, Longformer, Reformer, FlashAttention?  
35. Что дают 8-бит/4-бит квантизация и протоколы типа QLoRA?  
36. Зачем нужны Adapter-слои, LoRA, Prefix-tuning при дообучении?

J. Внутренняя кухня и анализ 
37. Как интерпретировать attention-карты: «видит ли» модель грамматику, плагины, числа?  
38. Что показывают матрицы sensitivity/обратного влияния (influence functions)?  
39. Как обнаружить «мертвые» или избыточные головы?  
40. Какие приёмы регуляризации специфичны для трансформеров (Stochastic Depth, DropHead)?

K. Разновидности и применения 
41. Что изменили в BERT, RoBERTa, ALBERT, ELECTRA?  
42. Как GPT-серия использует только декодер и causal objective?  
43. Что такое Vision Transformer (ViT) и почему ему достаточно патч-эмбеддинга?  
44. Как трансформеры применяют к аудио, видео и кросс-модальности (CLIP, Flamingo)?  
45. Какие hybrid-архитектуры «Conv + Transformer» или «RNN + Transformer» и почему они появляются?

L. Теория и ограничения 
46. Доказана ли универсальная аппроксимация для self-attention?  
47. Чем объясняется «большая игра в масштабирование» (scaling laws)?  
48. Какие лимиты накладывает феномен внимания на память и стабильность обучения?  
49. Почему трансформеры всё ещё плохо считают, логически выводят или хранят факты?  
50. Какие перспективы появления архитектур «после трансформера»?

