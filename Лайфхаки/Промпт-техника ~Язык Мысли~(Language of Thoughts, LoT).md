
Само исследование [https://arxiv.org/pdf/2505.12896](https://arxiv.org/pdf/2505.12896)


## 1. Ключевые аспекты исследования:

Исследование показывает, что большие языковые модели часто ошибаются не потому, что им не хватает знаний, а потому, что они "теряются" в предоставленном контексте. Авторы выделяют две ключевые проблемы: информация может быть сформулирована запутанно (локальная неявность) или "похоронена" среди нерелевантных деталей (контекстная неявность). Для решения этой проблемы предложена промпт-техника "Язык Мысли" (Language of Thoughts, LoT), которая заставляет модель сначала найти, перефразировать и перечислить все ключевые факты, и только потом давать финальный ответ.

**Ключевой результат:** Заставляя модель сначала "разложить все по полочкам" с помощью команд `expand` (расширь/переформулируй) и `echo` (повтори/перечисли), можно значительно повысить точность ее рассуждений и снизить влияние когнитивных искажений.

## 2. Объяснение всей сути метода:

Суть метода "Language of Thoughts" (LoT) заключается в том, чтобы перед решением основной задачи заставить LLM провести предварительную подготовку информации. Вместо того чтобы сразу бросаться "в бой", модель сначала выполняет два действия, которые имитируют человеческий процесс осмысления:

1. **Борьба с запутанными формулировками (L-implicitness):** Используется инструкция `expand` (расширь, раскрой, переформулируй). Она заставляет модель взять ключевую, но, возможно, сложно изложенную информацию и объяснить ее своими словами, сделать ее более явной. Например, вместо того чтобы просто принять факт "проект не соответствует ожиданиям", модель должна его "раскрыть": "Это означает, что сроки сорваны, бюджет превышен, а функционал реализован не полностью".
2. **Борьба с информационным шумом (Q-implicitness):** Используется инструкция `echo` (повтори, перечисли, выдели). Она заставляет модель просканировать весь контекст, отфильтровать нерелевантную информацию и четко перечислить только те факты, которые имеют прямое отношение к вопросу. Это как выписать ключевые данные из длинного текста на отдельный листок, чтобы ничего не упустить.

**Методика на практике:** В свой промпт, перед основной задачей, вы добавляете инструкцию, которая запускает этот двухэтапный процесс. Например: `"Прежде чем ответить на вопрос, давай сначала понаблюдаем, раскроем и перечислим всю релевантную информацию из текста. Затем, основываясь на этих выделенных фактах, дай пошаговый ответ."`

Этот подход заставляет модель создать для себя "шпаргалку" из ясных и отфильтрованных фактов, что резко снижает вероятность ошибок из-за невнимательности или неверной интерпретации.

## ---

## 3. Анализ практической применимости:

*Прямая применимость:Максимальная. Пользователь может взять готовую конструкциюPlease observe, expand, and echo all the relevant information(или ее русский аналог:Пожалуйста, изучи, раскрой и перечисли всю релевантную информацию) и вставить ее в свой промпт. Это работает "из коробки" и не требует никаких технических навыков. Метод особенно полезен, когда нужно проанализировать большой или запутанный текст.

- **Концептуальная ценность:** Очень высокая. Исследование дает пользователю мощную ментальную модель для отладки промптов. Если LLM дает неверный ответ на основе предоставленного текста, пользователь может задать себе два вопроса:

1. _Может, модель не нашла нужный факт в "стене текста"?_ → Нужно усилить `echo`-компонент ("Сначала выпиши все факты, связанные с [тема]").
2. _Может, модель неверно поняла сложную формулировку?_ → Нужно усилить `expand`-компонент ("Объясни простыми словами, что означает [сложная фраза]").

- **Потенциал для адаптации:** Огромный. Не обязательно использовать точные слова `expand` и `echo`. Механизм можно адаптировать под любую задачу:

- **Для анализа отзывов:** "Сначала выдели из каждого отзыва ключевые жалобы и похвалы. Перечисли их списком. Затем..."
- **Для планирования:** "Из этого диалога выпиши ограничения каждого участника (бюджет, даты, интересы). Сгруппируй их. Затем..."
- **Для юридического анализа:** "Сначала извлеки из договора все пункты, касающиеся ответственности сторон. Перечисли их дословно. Затем..."

---

## 4. Практически пример применения:

Ты — опытный маркетолог, анализирующий отзывы клиентов. Твоя задача — составить краткую сводку по проблемам и позитивным моментам на основе отзыва клиента.
**[Контекст: Отзыв клиента]**
"В целом, ваш новый сервис неплох. Зарегистрировался быстро, интерфейс понятный. Но ждал доставку почти две недели, хотя обещали 3 дня, курьер так и не позвонил заранее. Пытался написать в поддержку, отвечали роботы какими-то шаблонными фразами, живого человека так и не дождался. Сама вещь качественная, тут претензий нет, но цена, конечно, кусается. Не уверен, что буду заказывать снова из-за всего этого опыта с доставкой и поддержкой."

**[Задание]**
Проанализируй отзыв и подготовь структурированную сводку для отдела продукта.

**ВАЖНО:** Прежде чем дать финальный ответ, выполни следующие шаги:
1.  **Раскрой (Expand):** Возьми каждую нечеткую фразу из отзыва (например, "неплох", "цена кусается", "опыт с доставкой") и кратко раскрой ее значение на основе контекста.
2.  **Перечисли (Echo):** Четко выдели и перечисли списком все конкретные положительные и отрицательные моменты, упомянутые в отзыве.

И только после этого, на основе выделенных фактов, сформируй итоговую сводку.

## 5. Почему это работает:

Этот промпт работает за счет принудительной декомпозиции и фокусировки, которые лежат в основе метода LoT.

1. **Механика `Expand` (Раскрой):** Инструкция "Раскрой нечеткую фразу" заставляет модель бороться с **L-implicitness**. Вместо того чтобы проигнорировать фразу "цена кусается", модель вынуждена ее конкретизировать: "Клиент считает цену высокой, что является барьером для повторной покупки". Это превращает расплывчатое мнение в конкретный бизнес-инсайт.
2. **Механика `Echo` (Перечисли):** Инструкция "Перечисли... положительные и отрицательные моменты" заставляет модель бороться с **Q-implicitness**. Она не может просто выдать общую оценку, а вынуждена активно искать и извлекать отдельные факты из всего текста:

- (+) Быстрая регистрация
- (+) Понятный интерфейс
- (+) Качественный товар
- (-) Долгая доставка (2 недели вместо 3 дней)
- (-) Курьер не предупредил о визите
- (-) Плохая работа поддержки (шаблонные ответы роботов)
- (-) Высокая цена

Создав этот промежуточный, структурированный список, модель получает надежную основу для финальной сводки, минимизируя риск упустить важные детали или неверно их интерпретировать.

---

## 6. Другой пример практического применения

Ты — ассистент, который помогает составить план поездки на выходные для компании друзей на основе их переписки.
**[Контекст: Переписка в чате]**
- **Анна:** "Ребята, давайте куда-нибудь поедем на выходных! Я свободна в субботу и воскресенье. Бюджет у меня до 5000 рублей на все."
- **Виктор:** "Я за! Но в субботу до 15:00 я занят на курсах. И я не очень люблю музеи, лучше что-то активное на природе."
- **Ольга:** "Отличная идея! Я на машине, могу всех забрать. Главное, чтобы мы вернулись в город в воскресенье не позже 20:00, у меня в 21:00 поезд. По еде — я вегетарианка."

**[Задание]**
Предложи 1-2 варианта плана для поездки, которые учитывают все ограничения и пожелания.

**ИНСТРУКЦИЯ:** Прежде чем предлагать планы, выполни подготовительную работу:
1.  **Извлеки и перечисли (Echo):** Выпиши в виде списка все ключевые ограничения и пожелания КАЖДОГО участника (Анна, Виктор, Ольга). Сгруппируй их по именам.
2.  **Раскрой (Expand):** Кратко поясни, как каждое ограничение влияет на возможный план. Например, "Занятость Виктора до 15:00 в субботу означает, что выезжать из города нужно во второй половине дня субботы".

После этого анализа предложи итоговые варианты плана.

## 7. Объяснение механизма почему этот пример работает.

Этот промпт эффективно решает сложную задачу планирования с множеством ограничений благодаря применению принципов LoT.

1. **Механика `Echo` (Извлеки и перечисли):** Переписка друзей — это классический пример **Q-implicitness**. Важные факты (бюджет, время, предпочтения) разбросаны по разным сообщениям и перемешаны с "шумом" ("Ребята, давайте поедем!"). Инструкция "выпиши ограничения каждого участника" заставляет модель провести инвентаризацию всех условий:

- **Анна:** доступна Сб+Вс, бюджет < 5000 руб.
- **Виктор:** свободен с 15:00 Сб, хочет активный отдых, не любит музеи.
- **Ольга:** на машине, нужно вернуться в Вс до 20:00, вегетарианка. Этот шаг превращает хаотичную переписку в структурированную таблицу требований.

3. **Механика `Expand` (Раскрой и поясни):** Этот шаг помогает модели осмыслить последствия каждого ограничения. Это борется с потенциальной **L-implicitness**, когда простое условие "занят до 15:00" может быть неверно учтено. Проговаривая "это означает, что выезжать нужно после 15:00", модель сама себе создает четкое правило для планирования. То же самое с условием Ольги: "вегетарианство означает, что нужно либо искать места с соответствующим меню, либо планировать закупку продуктов".

### В результате, когда модель приступает к созданию плана, она оперирует не сырой перепиской, а четким, осмысленным списком требований, что практически гарантирует релевантный и выполнимый результат.

# Оценка полезности: 100

## Основные критерии оценки

- **A. Релевантность техникам промтинга:** Да, исследование предлагает конкретную технику "Language of Thoughts" (LoT) с готовыми фразами-инструкциями (`observe, expand, and echo`).
- **B. Улучшение качества диалоговых ответов:** Да, исследование демонстрирует значительное улучшение точности и снижение предвзятости на 11 различных бенчмарках, включая задачи на здравый смысл и логику.
- **C. Прямая практическая применимость:** Абсолютно. Метод не требует кода или специальных инструментов. Пользователь может немедленно вставить предложенные фразы в свои промпты в любом чат-боте.
- **D. Концептуальная ценность:** Очень высокая. Работа вводит простую и мощную ментальную модель двух типов "неявности" информации (L-implicitness и Q-implicitness), которая помогает пользователю понять, _почему_ его промпты могут не работать, и как это исправить.
- **E. Новая полезная практика (Кластеры):**

- **Кластер 1 (Техники):** Да, LoT — это новая техника, похожая на Chain-of-Thought.
- **Кластер 2 (Поведенческие закономерности):** Да, раскрывает, как LLM "отвлекается" на нерелевантный контекст или "путается" в сложных формулировках.
- **Кластер 7 (Надежность и стабильность):** Да, основная цель — снизить количество ошибок и предвзятых ответов.

- **Чек-лист практичности (+15 баллов):** Даны готовые фразы, показано, как структурировать сложные запросы, раскрыты неочевидные особенности поведения LLM и предложены способы улучшить точность. Бонус в 15 баллов применен.

## Цифровая оценка полезности

Исследование получает максимальный балл, так как представляет собой идеальный пример практической научной работы для промпт-инженеров. Оно не только предлагает готовую к использованию и эффективную технику, но и дает глубокое концептуальное понимание того, как и почему LLM совершают ошибки.

**Аргументы за оценку:** 1. **Прямое действие:** Техника LoT — это готовый инструмент. Фразы "observe, expand, and echo" можно скопировать и сразу получить результат. 2. **Диагностическая ценность:** Концепции L- и Q-неявности позволяют пользователю не просто пробовать разные промпты вслепую, а диагностировать проблему: "Модель не видит важную информацию в тексте?" (Q-implicitness) или "Модель неправильно поняла сложную формулировку?" (L-implicitness). 3. **Широкая применимость:** Эффективность доказана на множестве моделей (GPT-4o, Llama 3, Qwen2) и задач (логика, здравый смысл, анализ текста), что говорит об универсальности подхода.

**Контраргументы (почему оценка могла бы быть ниже):** 1. **Сложность для новичков:** Сама научная статья написана сложным академическим языком. Без подобного разбора обычному пользователю было бы трудно извлечь из нее суть. 2. **Увеличение стоимости:** Применение техник `expand` и `echo` заставляет модель генерировать больше текста на промежуточном этапе, что может увеличить расход токенов и стоимость запросов через API. 3. **Ограничения для слабых моделей:** Авторы сами отмечают, что маленькие модели или модели с плохим следованием инструкциям могут не справиться с выполнением промпта LoT, что несколько снижает его универсальность.